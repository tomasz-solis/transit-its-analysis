{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness Checks: Realistic Dataset\n",
    "\n",
    "**Author:** Tomasz Solis  \n",
    "**Date:** December 2025  \n",
    "**Goal:** Test if realistic ITS results hold under stress tests\n",
    "\n",
    "## Context\n",
    "\n",
    "Notebook 04 found mixed results:\n",
    "- Downtown: +53 riders (significant)\n",
    "- Suburban: +23 riders (not significant)\n",
    "- Cross-town: +7 riders (not significant)\n",
    "\n",
    "**Baseline robustness (notebook 03):**\n",
    "- Placebo: PASSED (16% of real effects)\n",
    "- Window: EXCELLENT (<5% variation)\n",
    "- Specs: EXCELLENT (<6% variation)\n",
    "\n",
    "**Expected for realistic:**\n",
    "- MORE sensitivity (high noise + small effects)\n",
    "- Some placebo false positives possible\n",
    "- More variation across specifications\n",
    "- Still directionally robust\n",
    "\n",
    "**What I'm testing:**\n",
    "Same 4 checks as baseline, but expecting messier results. This teaches how to interpret robustness on real-world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Setup complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "fig_output_dir = Path(\"../outputs/figures\")\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "ROUTE_COLORS = {\n",
    "    'Downtown': '#1f77b4',\n",
    "    'Suburban': '#ff7f0e',\n",
    "    'Cross-town': '#2ca02c'\n",
    "}\n",
    "\n",
    "REAL_INTERVENTION = datetime(2024, 1, 1)\n",
    "baseline_results = {'Downtown': 53.0, 'Suburban': 23.4, 'Cross-town': 7.2}\n",
    "\n",
    "print(\"\u2713 Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 783 observations\n",
      "Pre-intervention: 624 observations\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/hard_mode/transit_ridership_realistic.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df_pre = df[df['date'] < REAL_INTERVENTION].copy()\n",
    "\n",
    "print(f\"Loaded {len(df):,} observations\")\n",
    "print(f\"Pre-intervention: {len(df_pre):,} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Placebo Tests\n",
    "\n",
    "Test fake intervention dates before Jan 2024. With high noise, we might see some false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running placebo tests...\n",
      "\n",
      "============================================================\n",
      "PLACEBO TEST SUMMARY\n",
      "============================================================\n",
      "Tests run: 12\n",
      "Significant (p<0.05): 3 (25%)\n",
      "Estimate range: [-68.8, +14.4]\n",
      "Mean: -18.2 riders\n",
      "\n",
      "Largest placebo: 68.8 riders\n",
      "Smallest real effect: 7.2 riders\n",
      "Ratio: 955.0%\n",
      "\n",
      "Expected false positives: 0.6\n",
      "Observed significant: 3\n",
      "\n",
      "\u274c CONCERNING: High placebo sensitivity\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def run_placebo_test(data, route_type, fake_intervention_date, maxlags=4):\n",
    "    \"\"\"Run ITS with fake intervention date.\"\"\"\n",
    "    route_data = data[data['route_type'] == route_type].copy()\n",
    "    route_data = route_data.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    route_data['fake_post'] = (route_data['date'] >= fake_intervention_date).astype(float)\n",
    "    route_data['fake_time_since'] = route_data.apply(\n",
    "        lambda row: max(0, (row['date'] - fake_intervention_date).days / 7) if row['fake_post'] else 0,\n",
    "        axis=1\n",
    "    )\n",
    "    route_data['fake_time'] = (route_data['date'] - route_data['date'].min()).dt.days / 7\n",
    "    \n",
    "    y = route_data['avg_ridership'].values\n",
    "    X = pd.DataFrame({\n",
    "        'time': route_data['fake_time'].values.astype(float),\n",
    "        'post_intervention': route_data['fake_post'].values.astype(float),\n",
    "        'time_since_intervention': route_data['fake_time_since'].values.astype(float)\n",
    "    })\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    \n",
    "    model = OLS(y, X.values)\n",
    "    results = model.fit(cov_type='HAC', cov_kwds={'maxlags': maxlags})\n",
    "    \n",
    "    params = dict(zip(X.columns, results.params))\n",
    "    se = dict(zip(X.columns, results.bse))\n",
    "    pvalues = dict(zip(X.columns, results.pvalues))\n",
    "    \n",
    "    beta_2 = params['post_intervention']\n",
    "    se_2 = se['post_intervention']\n",
    "    \n",
    "    return {\n",
    "        'route': route_type,\n",
    "        'fake_date': fake_intervention_date,\n",
    "        'beta_2': beta_2,\n",
    "        'se': se_2,\n",
    "        'p_value': pvalues['post_intervention'],\n",
    "        'significant': pvalues['post_intervention'] < 0.05\n",
    "    }\n",
    "\n",
    "# Run placebo tests\n",
    "fake_dates = [\n",
    "    datetime(2022, 1, 1),\n",
    "    datetime(2022, 7, 1),\n",
    "    datetime(2023, 1, 1),\n",
    "    datetime(2023, 7, 1),\n",
    "]\n",
    "\n",
    "print(\"Running placebo tests...\")\n",
    "placebo_results = []\n",
    "for fake_date in fake_dates:\n",
    "    for route in ['Downtown', 'Suburban', 'Cross-town']:\n",
    "        result = run_placebo_test(df_pre, route, fake_date, maxlags=4)\n",
    "        placebo_results.append(result)\n",
    "\n",
    "placebo_df = pd.DataFrame(placebo_results)\n",
    "\n",
    "# Summary\n",
    "n_significant = placebo_df['significant'].sum()\n",
    "mean_placebo = placebo_df['beta_2'].mean()\n",
    "max_placebo = placebo_df['beta_2'].abs().max()\n",
    "min_real_effect = min(baseline_results.values())\n",
    "ratio = max_placebo / min_real_effect\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PLACEBO TEST SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Tests run: {len(placebo_df)}\")\n",
    "print(f\"Significant (p<0.05): {n_significant} ({n_significant/len(placebo_df)*100:.0f}%)\")\n",
    "print(f\"Estimate range: [{placebo_df['beta_2'].min():+.1f}, {placebo_df['beta_2'].max():+.1f}]\")\n",
    "print(f\"Mean: {mean_placebo:+.1f} riders\")\n",
    "print(f\"\\nLargest placebo: {max_placebo:.1f} riders\")\n",
    "print(f\"Smallest real effect: {min_real_effect:.1f} riders\")\n",
    "print(f\"Ratio: {ratio:.1%}\")\n",
    "\n",
    "# More lenient criteria for realistic data\n",
    "expected_false_pos = len(placebo_df) * 0.05\n",
    "print(f\"\\nExpected false positives: {expected_false_pos:.1f}\")\n",
    "print(f\"Observed significant: {n_significant}\")\n",
    "\n",
    "if ratio < 0.5 and n_significant <= expected_false_pos + 2:\n",
    "    print(f\"\\n\u2713 ACCEPTABLE: Placebo estimates reasonable given noise\")\n",
    "    print(f\"  Ratio {ratio:.0%} shows placebos smaller than real effects\")\n",
    "elif ratio < 1.0:\n",
    "    print(f\"\\n\u26a0\ufe0f  BORDERLINE: Some placebo sensitivity\")\n",
    "    print(f\"  Ratio {ratio:.0%} - placebos approaching real effect magnitudes\")\n",
    "else:\n",
    "    print(f\"\\n\u274c CONCERNING: High placebo sensitivity\")\n",
    "\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:** High noise means some placebo false positives are expected. Key is that magnitude stays smaller than real effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Window Sensitivity\n",
    "\n",
    "Test 1-4 years of pre-data. Confounders (especially competitor) may cause more variation than baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing window sensitivity...\n",
      "\n",
      "============================================================\n",
      "WINDOW SENSITIVITY\n",
      "============================================================\n",
      "\n",
      "Downtown:\n",
      "  Baseline (4yr): +53.0\n",
      "  Range: [+53.0, +67.8]\n",
      "  Variation: 27.9%\n",
      "\n",
      "Suburban:\n",
      "  Baseline (4yr): +23.4\n",
      "  Range: [+23.4, +36.2]\n",
      "  Variation: 54.7%\n",
      "\n",
      "Cross-town:\n",
      "  Baseline (4yr): +7.2\n",
      "  Range: [+7.2, +13.2]\n",
      "  Variation: 83.4%\n",
      "\n",
      "Max variation: 83.4%\n",
      "\u274c HIGH: Very sensitive to window choice\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def fit_its_window(data, route_type, start_date, maxlags=4):\n",
    "    \"\"\"Fit ITS using specific time window.\"\"\"\n",
    "    route_data = data[\n",
    "        (data['route_type'] == route_type) & \n",
    "        (data['date'] >= start_date)\n",
    "    ].copy()\n",
    "    \n",
    "    route_data = route_data.sort_values('date').reset_index(drop=True)\n",
    "    route_data['window_time'] = (route_data['date'] - route_data['date'].min()).dt.days / 7\n",
    "    \n",
    "    y = route_data['avg_ridership'].values\n",
    "    X = pd.DataFrame({\n",
    "        'time': route_data['window_time'].values.astype(float),\n",
    "        'post_intervention': route_data['post_intervention'].values.astype(float),\n",
    "        'time_since_intervention': route_data['time_since_intervention'].values.astype(float)\n",
    "    })\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    \n",
    "    model = OLS(y, X.values)\n",
    "    results = model.fit(cov_type='HAC', cov_kwds={'maxlags': maxlags})\n",
    "    \n",
    "    params = dict(zip(X.columns, results.params))\n",
    "    beta_2 = params['post_intervention']\n",
    "    \n",
    "    return {'route': route_type, 'level_change': beta_2}\n",
    "\n",
    "windows = [\n",
    "    datetime(2020, 1, 1),  # 4 years\n",
    "    datetime(2021, 1, 1),  # 3 years\n",
    "    datetime(2022, 1, 1),  # 2 years\n",
    "    datetime(2023, 1, 1),  # 1 year\n",
    "]\n",
    "\n",
    "print(\"Testing window sensitivity...\")\n",
    "window_results = []\n",
    "for start_date in windows:\n",
    "    for route in ['Downtown', 'Suburban', 'Cross-town']:\n",
    "        result = fit_its_window(df, route, start_date)\n",
    "        window_results.append(result)\n",
    "\n",
    "window_df = pd.DataFrame(window_results)\n",
    "\n",
    "# Summary\n",
    "max_variation = 0\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"WINDOW SENSITIVITY\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for route in ['Downtown', 'Suburban', 'Cross-town']:\n",
    "    route_windows = window_df[window_df['route'] == route]\n",
    "    original = baseline_results[route]\n",
    "    estimates = route_windows['level_change'].values\n",
    "    variation = ((estimates.max() - estimates.min()) / abs(original)) * 100\n",
    "    max_variation = max(max_variation, variation)\n",
    "    \n",
    "    print(f\"\\n{route}:\")\n",
    "    print(f\"  Baseline (4yr): {original:+.1f}\")\n",
    "    print(f\"  Range: [{estimates.min():+.1f}, {estimates.max():+.1f}]\")\n",
    "    print(f\"  Variation: {variation:.1f}%\")\n",
    "\n",
    "print(f\"\\nMax variation: {max_variation:.1f}%\")\n",
    "\n",
    "if max_variation < 25:\n",
    "    print(\"\u2713 ACCEPTABLE: Reasonably stable across windows\")\n",
    "elif max_variation < 50:\n",
    "    print(\"\u26a0\ufe0f  MODERATE: Some window sensitivity (expected with confounders)\")\n",
    "else:\n",
    "    print(\"\u274c HIGH: Very sensitive to window choice\")\n",
    "\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:** More variation than baseline expected. Confounders affect different time windows differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Leave-One-Out\n",
    "\n",
    "Same as baseline - should still show 0% deviation (segment-specific models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running leave-one-out...\n",
      "\n",
      "============================================================\n",
      "LEAVE-ONE-OUT\n",
      "============================================================\n",
      "\n",
      "Downtown: 0.0% max deviation\n",
      "\n",
      "Suburban: 0.1% max deviation\n",
      "\n",
      "Cross-town: 0.5% max deviation\n",
      "\n",
      "Overall: 0.5% max deviation\n",
      "\n",
      "Note: 0% expected with segment-specific models (same as baseline)\n",
      "Confirms routes are independent segments.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def fit_its_leave_one_out(data, excluded_route, maxlags=4):\n",
    "    \"\"\"Fit ITS excluding one route.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for route in ['Downtown', 'Suburban', 'Cross-town']:\n",
    "        if route == excluded_route:\n",
    "            continue\n",
    "            \n",
    "        route_data = data[data['route_type'] == route].copy()\n",
    "        route_data = route_data.sort_values('date').reset_index(drop=True)\n",
    "        route_data['model_time'] = (route_data['date'] - route_data['date'].min()).dt.days / 7\n",
    "        \n",
    "        y = route_data['avg_ridership'].values\n",
    "        X = pd.DataFrame({\n",
    "            'time': route_data['model_time'].values.astype(float),\n",
    "            'post_intervention': route_data['post_intervention'].values.astype(float),\n",
    "            'time_since_intervention': route_data['time_since_intervention'].values.astype(float)\n",
    "        })\n",
    "        X = sm.add_constant(X, has_constant='add')\n",
    "        \n",
    "        model = OLS(y, X.values)\n",
    "        fitted = model.fit(cov_type='HAC', cov_kwds={'maxlags': maxlags})\n",
    "        params = dict(zip(X.columns, fitted.params))\n",
    "        \n",
    "        results[route] = {\n",
    "            'excluded': excluded_route,\n",
    "            'route': route,\n",
    "            'level_change': params['post_intervention']\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Running leave-one-out...\")\n",
    "loo_results = []\n",
    "for excluded in ['Downtown', 'Suburban', 'Cross-town']:\n",
    "    results = fit_its_leave_one_out(df, excluded)\n",
    "    for res in results.values():\n",
    "        loo_results.append(res)\n",
    "\n",
    "loo_df = pd.DataFrame(loo_results)\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"LEAVE-ONE-OUT\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "max_deviation = 0\n",
    "for route in ['Downtown', 'Suburban', 'Cross-town']:\n",
    "    original = baseline_results[route]\n",
    "    route_loo = loo_df[loo_df['route'] == route]\n",
    "    \n",
    "    deviations = [abs((row['level_change'] - original) / original) * 100 \n",
    "                 for _, row in route_loo.iterrows()]\n",
    "    max_dev = max(deviations) if deviations else 0\n",
    "    max_deviation = max(max_deviation, max_dev)\n",
    "    \n",
    "    print(f\"\\n{route}: {max_dev:.1f}% max deviation\")\n",
    "\n",
    "print(f\"\\nOverall: {max_deviation:.1f}% max deviation\")\n",
    "print(\"\\nNote: 0% expected with segment-specific models (same as baseline)\")\n",
    "print(\"Confirms routes are independent segments.\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:** Same as baseline - 0% deviation confirms segment-specific approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Alternative Specifications\n",
    "\n",
    "Test lag variations and boundary exclusions. Expect more sensitivity than baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing alternative specifications...\n",
      "\n",
      "============================================================\n",
      "ALTERNATIVE SPECIFICATIONS\n",
      "============================================================\n",
      "\n",
      "Downtown:\n",
      "  Baseline: +53.0\n",
      "  Range: [+20.3, +53.0]\n",
      "  Max deviation: 61.7%\n",
      "\n",
      "Suburban:\n",
      "  Baseline: +23.4\n",
      "  Range: [+23.4, +46.3]\n",
      "  Max deviation: 97.7%\n",
      "\n",
      "Cross-town:\n",
      "  Baseline: +7.2\n",
      "  Range: [+2.8, +13.6]\n",
      "  Max deviation: 89.5%\n",
      "\n",
      "Worst deviation: 97.7%\n",
      "\u274c HIGH: Very sensitive to specification\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def test_newey_west_lags(data, route_type, lags):\n",
    "    \"\"\"Test different Newey-West lag specifications.\"\"\"\n",
    "    route_data = data[data['route_type'] == route_type].copy()\n",
    "    route_data = route_data.sort_values('date').reset_index(drop=True)\n",
    "    route_data['model_time'] = (route_data['date'] - route_data['date'].min()).dt.days / 7\n",
    "    \n",
    "    y = route_data['avg_ridership'].values\n",
    "    X = pd.DataFrame({\n",
    "        'time': route_data['model_time'].values.astype(float),\n",
    "        'post_intervention': route_data['post_intervention'].values.astype(float),\n",
    "        'time_since_intervention': route_data['time_since_intervention'].values.astype(float)\n",
    "    })\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    \n",
    "    model = OLS(y, X.values)\n",
    "    results = model.fit(cov_type='HAC', cov_kwds={'maxlags': lags})\n",
    "    params = dict(zip(X.columns, results.params))\n",
    "    \n",
    "    return {'route': route_type, 'spec': f'NW lag {lags}', 'beta_2': params['post_intervention']}\n",
    "\n",
    "def test_boundary_exclusion(data, route_type, exclude_first=0, exclude_last=0):\n",
    "    \"\"\"Test excluding boundary periods.\"\"\"\n",
    "    route_data = data[data['route_type'] == route_type].copy()\n",
    "    route_data = route_data.sort_values('date').reset_index(drop=True)\n",
    "    \n",
    "    route_data['weeks_post'] = route_data.apply(\n",
    "        lambda row: (row['date'] - REAL_INTERVENTION).days / 7 if row['post_intervention'] == 1 else -999,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    if exclude_first > 0 or exclude_last > 0:\n",
    "        mask = (\n",
    "            (route_data['post_intervention'] == 0) |\n",
    "            ((route_data['weeks_post'] > exclude_first) & (route_data['weeks_post'] <= (52 - exclude_last)))\n",
    "        )\n",
    "        route_data = route_data[mask].copy()\n",
    "    \n",
    "    route_data['model_time'] = (route_data['date'] - route_data['date'].min()).dt.days / 7\n",
    "    y = route_data['avg_ridership'].values\n",
    "    X = pd.DataFrame({\n",
    "        'time': route_data['model_time'].values.astype(float),\n",
    "        'post_intervention': route_data['post_intervention'].values.astype(float),\n",
    "        'time_since_intervention': route_data['time_since_intervention'].values.astype(float)\n",
    "    })\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    \n",
    "    model = OLS(y, X.values)\n",
    "    results = model.fit(cov_type='HAC', cov_kwds={'maxlags': 4})\n",
    "    params = dict(zip(X.columns, results.params))\n",
    "    \n",
    "    return {\n",
    "        'route': route_type,\n",
    "        'spec': f'Excl F{exclude_first}L{exclude_last}',\n",
    "        'beta_2': params['post_intervention']\n",
    "    }\n",
    "\n",
    "print(\"Testing alternative specifications...\")\n",
    "\n",
    "alt_results = []\n",
    "\n",
    "# Lag tests\n",
    "for lags in [2, 4, 6, 8]:\n",
    "    for route in ['Downtown', 'Suburban', 'Cross-town']:\n",
    "        alt_results.append(test_newey_west_lags(df, route, lags))\n",
    "\n",
    "# Boundary tests\n",
    "for exclude_first, exclude_last in [(4, 0), (0, 4), (4, 4)]:\n",
    "    for route in ['Downtown', 'Suburban', 'Cross-town']:\n",
    "        alt_results.append(test_boundary_exclusion(df, route, exclude_first, exclude_last))\n",
    "\n",
    "alt_df = pd.DataFrame(alt_results)\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ALTERNATIVE SPECIFICATIONS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "worst_dev = 0\n",
    "for route in ['Downtown', 'Suburban', 'Cross-town']:\n",
    "    route_alts = alt_df[alt_df['route'] == route]\n",
    "    baseline = baseline_results[route]\n",
    "    estimates = route_alts['beta_2'].values\n",
    "    \n",
    "    deviations = [abs((est - baseline) / baseline) * 100 for est in estimates]\n",
    "    max_dev = max(deviations)\n",
    "    worst_dev = max(worst_dev, max_dev)\n",
    "    \n",
    "    print(f\"\\n{route}:\")\n",
    "    print(f\"  Baseline: {baseline:+.1f}\")\n",
    "    print(f\"  Range: [{estimates.min():+.1f}, {estimates.max():+.1f}]\")\n",
    "    print(f\"  Max deviation: {max_dev:.1f}%\")\n",
    "\n",
    "print(f\"\\nWorst deviation: {worst_dev:.1f}%\")\n",
    "\n",
    "if worst_dev < 25:\n",
    "    print(\"\u2713 GOOD: Stable across specs\")\n",
    "elif worst_dev < 50:\n",
    "    print(\"\u26a0\ufe0f  MODERATE: Some spec sensitivity (expected with noise)\")\n",
    "else:\n",
    "    print(\"\u274c HIGH: Very sensitive to specification\")\n",
    "\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:** More variation than baseline expected. Small effects + high noise = more sensitivity to modeling choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "**Robustness checks completed:**\n",
    "1. Placebo tests\n",
    "2. Window sensitivity\n",
    "3. Leave-one-out\n",
    "4. Alternative specifications\n",
    "\n",
    "**Comparison to baseline:**\n",
    "\n",
    "| Test | Baseline (Clean) | Realistic (Messy) |\n",
    "|------|------------------|-------------------|\n",
    "| Placebo | 16% ratio, 0/12 sig | 955% ratio, 3/12 sig \u26a0\ufe0f |\n",
    "| Window | <5% variation | 28-83% variation \u26a0\ufe0f |\n",
    "| Leave-one-out | 0% deviation | 0% deviation \u2713 |\n",
    "| Specifications | <6% deviation | 62-98% deviation \u26a0\ufe0f |\n",
    "\n",
    "**Pattern observed:**\n",
    "- Much MORE sensitivity than baseline (as expected)\n",
    "- But sensitivity is SEVERE, not moderate\n",
    "- Leave-one-out still 0% (segment approach correct)\n",
    "- Results do NOT survive variations well\n",
    "\n",
    "**What this teaches:**\n",
    "\n",
    "**Baseline robustness:** \"Results are extremely stable - strong evidence\"\n",
    "\n",
    "**Realistic robustness:** \"Results are fragile - weak evidence\"\n",
    "\n",
    "The key difference:\n",
    "- **Baseline:** Robust to everything (placebo, window, specs)\n",
    "- **Realistic:** Fragile to everything (except segmentation)\n",
    "\n",
    "**Why results are fragile:**\n",
    "\n",
    "1. **Placebo tests show red flags**\n",
    "   - Finding effects larger than real effects in fake dates\n",
    "   - 25% false positive rate (vs expected 5%)\n",
    "   - Model picking up noise, not just signal\n",
    "\n",
    "2. **Window sensitivity is high**\n",
    "   - Cross-town: 83% variation (completely unreliable)\n",
    "   - Suburban: 55% variation (very sensitive)\n",
    "   - Downtown: 28% variation (least bad, but still high)\n",
    "\n",
    "3. **Specification sensitivity is very high**\n",
    "   - Suburban: 98% variation (modeling choices dominate)\n",
    "   - Cross-town: 90% variation\n",
    "   - Downtown: 62% variation\n",
    "   - Which model is \"right\"? Can't tell.\n",
    "\n",
    "**Combined evidence (notebooks 04-06):**\n",
    "\n",
    "**Downtown:**\n",
    "- Point estimate: +53 riders\n",
    "- Significant in main spec\n",
    "- BUT: 62% spec sensitivity, 28% window sensitivity\n",
    "- Assessment: Directional positive signal, but imprecise\n",
    "\n",
    "**Suburban:**\n",
    "- Point estimate: +23 riders\n",
    "- NOT significant\n",
    "- 98% spec sensitivity (worst case scenario)\n",
    "- Assessment: Cannot reliably distinguish from noise\n",
    "\n",
    "**Cross-town:**\n",
    "- Point estimate: +7 riders\n",
    "- NOT significant\n",
    "- 83% window, 90% spec sensitivity\n",
    "- Assessment: Effect too small to detect given noise\n",
    "\n",
    "**Competitor confounder:**\n",
    "Remains fundamental limitation - biases counterfactual downward, potentially inflating all estimates.\n",
    "\n",
    "**Final assessment:**\n",
    "\n",
    "These results show **fragile evidence**, not just uncertainty:\n",
    "\n",
    "**What happened:**\n",
    "- High noise (3x baseline) overwhelmed small effects\n",
    "- Competitor confounder created identification problem\n",
    "- Placebo tests revealing we're partly measuring noise\n",
    "- Sensitivity tests showing modeling choices dominate results\n",
    "\n",
    "**What we can say:**\n",
    "- Downtown: Directional evidence of positive effect, but can't quantify precisely\n",
    "- Suburban/Cross-town: Effects not reliably detectable above noise\n",
    "\n",
    "**What we CANNOT say:**\n",
    "- Cannot claim \"results useful for decisions\" - too fragile\n",
    "- Cannot quantify effects with confidence\n",
    "- Cannot rule out that estimates are mostly noise + competitor bias\n",
    "\n",
    "**In practice, I would report:**\n",
    "\n",
    "\"Analysis inconclusive. ITS methodology applied correctly, but data quality insufficient for reliable conclusions. Competitor confounder (Jul 2023) and high noise prevent clean measurement. Downtown shows directional positive signal, but precision too low for ROI calculations. Suburban/Cross-town effects not detectable. \n",
    "\n",
    "Recommendations: \n",
    "(1) Wait 6-12 months for more post-data to improve precision\n",
    "(2) Consider complementary analysis (surveys, A/B tests on future features)\n",
    "(3) Acknowledge we cannot measure this intervention's impact reliably with current data\"\n",
    "\n",
    "**Key learning:**\n",
    "\n",
    "This is what happens when ITS assumptions are badly violated:\n",
    "- You get point estimates, but can't trust them\n",
    "- Robustness checks reveal fragility\n",
    "- Honest answer: \"We can't measure this cleanly\"\n",
    "\n",
    "Being transparent about weak evidence is more valuable than overselling it. Sometimes the data just can't answer the question reliably, and acknowledging that is good analytics practice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}